{
    "type": [
        2,
        2,
        3,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        3,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        0,
        1,
        0,
        1,
        2,
        0,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        0,
        1,
        0,
        1,
        2
    ],
    "data": [
        "\nR version 4.3.3 (2024-02-29) -- \"Angel Food Cake\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-pc-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how ",
        "to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\n",
        "Error in python_config_impl(python) : \n  Error running '/home/abdoul/.virtualenvs/r-reticulate/bin/python': No such file.\nThe Python installation used to create the virtualenv has been moved or removed:\n  '/usr/bin'\n",
        "> ",
        "x = NULL",
        "> ",
        "is.null(x)",
        "[1] TRUE\n",
        "> ",
        "?glmnet::glmnet",
        "> ",
        "roxygen2::roxygenize()",
        "\u001B[38;5;254m\u001B[36mℹ\u001B[38;5;254m Loading \u001B[34mAdapDiscom\u001B[38;5;254m\u001B[39m\n\u001B[38;5;254m\u001B[31m✖\u001B[38;5;254m \u001B]8;line = 20:col = 1;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/R/adapdiscom.R\u0007adapdiscom.R:20\u001B]8;;\u0007: \u001B[1m@details\u001B[22m requires a value.\u001B[39m\n\u001B[38;5;254m\u001B[31m✖\u001B[38;5;254m \u001B]8;line = 22:col = 1;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/R/discom.R\u0007discom.R:22\u001B]8;;\u0007: \u001B[1m@details\u001B[22m requires a value.\u001B[39m\n\u001B[38;5;254m\u001B[31m✖\u001B[38;5;254m \u001B]8;line = 23:col = 1;file:///home/abdou",
        "l/Desktop/AdapDiscom/AdapDiscomPackage/R/fast_variants.R\u0007fast_variants.R:23\u001B]8;;\u0007: \u001B[1m@details\u001B[22m requires a value.\u001B[39m\n\u001B[38;5;254m\u001B[31m✖\u001B[38;5;254m \u001B]8;line = 300:col = 1;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/R/fast_variants.R\u0007fast_variants.R:300\u001B]8;;\u0007: \u001B[1m@details\u001B[22m requires a value.\u001B[39m\n\u001B[38;5;254m\u001B[31m✖\u001B[38;5;254m Skipping \u001B]8;;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/NAMESPACE\u0007\u001B[34mNAMESPACE\u001B[38;5;254m\u001B]8;;\u0007\n\u001B[36mℹ\u001B[38;5;254m It already exists and was n",
        "ot generated by roxygen2.\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('adapdiscom')\u0007\u001B[34madapdiscom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('discom')\u0007\u001B[34mdiscom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('fast_adapdiscom')\u0007\u001B[34mfast_adapdiscom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('fast_discom')\u0007\u001B[34mfast_discom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n",
        "> ",
        "roxygen2::roxygenize()",
        "\u001B[38;5;254m\u001B[36mℹ\u001B[38;5;254m Loading \u001B[34mAdapDiscom\u001B[38;5;254m\u001B[39m\n\u001B[38;5;254m\u001B[31m✖\u001B[38;5;254m Skipping \u001B]8;;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/NAMESPACE\u0007\u001B[34mNAMESPACE\u001B[38;5;254m\u001B]8;;\u0007\n\u001B[36mℹ\u001B[38;5;254m It already exists and was not generated by roxygen2.\u001B[39m\n",
        "> ",
        "roxygen2::roxygenize()",
        "\u001B[38;5;254m\u001B[36mℹ\u001B[38;5;254m Loading \u001B[34mAdapDiscom\u001B[38;5;254m\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/NAMESPACE\u0007\u001B[34mNAMESPACE\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n",
        "> ",
        "roxygen2::vignette_roclet()",
        "list()\nattr(,\"class\")\n[1] \"roclet_vignette\" \"roclet\"         \n",
        "> ",
        "library(roxygen2)",
        "> ",
        "roxygenize()",
        "\u001B[38;5;254mWriting \u001B]8;;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/NAMESPACE\u0007\u001B[34mNAMESPACE\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254m\u001B[36mℹ\u001B[38;5;254m Loading \u001B[34mAdapDiscom\u001B[38;5;254m\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('adapdiscom')\u0007\u001B[34madapdiscom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('discom')\u0007\u001B[34mdiscom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('fast_adapdiscom')\u0007\u001B[34mfast_adapdiscom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[",
        "39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('fast_discom')\u0007\u001B[34mfast_discom.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;x-r-run:pkgload::dev_help('fit_standardize_x')\u0007\u001B[34mfit_standardize_x.Rd\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n",
        "> ",
        "roxygenize()",
        "\u001B[38;5;254m\u001B[36mℹ\u001B[38;5;254m Loading \u001B[34mAdapDiscom\u001B[38;5;254m\u001B[39m\n\u001B[38;5;254mWriting \u001B]8;;file:///home/abdoul/Desktop/AdapDiscom/AdapDiscomPackage/NAMESPACE\u0007\u001B[34mNAMESPACE\u001B[38;5;254m\u001B]8;;\u0007\u001B[39m\n\nRestarting R session...\n\n",
        "Error in python_config_impl(python) : \n  Error running '/home/abdoul/.virtualenvs/r-reticulate/bin/python': No such file.\nThe Python installation used to create the virtualenv has been moved or removed:\n  '/usr/bin'\n",
        "> ",
        "library(AdapDiscom)",
        "> ",
        "library(MASS)",
        "> ",
        "> ",
        "# Set parameters",
        "> ",
        "n <- 100        # Training sample size",
        "> ",
        "n.tuning <- 50  # Tuning sample size  ",
        "> ",
        "n.test <- 50    # Test sample size",
        "> ",
        "p <- 50         # Number of variables",
        "> ",
        "pp <- c(20, 15, 15)  # Block sizes (must sum to p)",
        "> ",
        "> ",
        "# Generate block-diagonal covariance matrix",
        "> ",
        "Sigma <- generate.cov(p, example = 2)  # Block diagonal structure",
        "> ",
        "> ",
        "# Generate true beta coefficients",
        "> ",
        "beta.true <- c(rep(2, 10), rep(0, 10), rep(1, 10), rep(0, 5), rep(-1, 10), rep(0, 5))",
        "> ",
        "> ",
        "# Generate training data",
        "> ",
        "X.train <- mvrnorm(n, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.train <- X.train %*% beta.true + rnorm(n)",
        "> ",
        "> ",
        "# Generate tuning data",
        "> ",
        "X.tuning <- mvrnorm(n.tuning, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.tuning <- X.tuning %*% beta.true + rnorm(n.tuning)",
        "> ",
        "> ",
        "# Generate test data",
        "> ",
        "X.test <- mvrnorm(n.test, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.test <- X.test %*% beta.true + rnorm(n.test)",
        "> ",
        "X.train",
        "              [,1]         [,2]         [,3]          [,4]        [,5]\n  [1,]  0.13403348  1.240202089  2.103455434  2.3458091745  1.04094980\n  [2,] -1.98868530 -1.067516083 -1.218810135 -1.4856529249 -2.32627915\n  [3,] -0.10930270  0.310510331  0.479658116  1.4134271858  0.00724232\n  [4,]  1.31514575 -0.350178221 -1.286848831  0.2578845701 -1.24519891\n  [5,]  1.58848708 -1.349141380  0.736440740  0.1227550987 -0.81670510\n  [6,]  0.43229516 -0.034145048 -1.627236384  0.1342898599 -0.74550274\n  [7,]  0.76973",
        "567 -0.604176479  0.621178985  0.1271326304 -1.44849997\n  [8,] -0.04256012  0.388798323  0.324258667  0.7861844439 -0.02690446\n  [9,] -1.78029562 -0.106877264 -0.163944703  0.2938284822 -1.27251280\n [10,] -1.98474981 -0.303482545 -0.025246266 -0.2657092228  0.72066960\n [11,]  0.33237104 -0.720324742  1.042986460  1.5084219292  0.82501488\n [12,] -1.48309015 -0.767908343 -1.335498937 -1.5350864312 -0.94652326\n [13,]  0.68422325  0.386395786 -1.322492379 -0.7789865815  0.75228929\n [14,] -1.12748850 -1.30494575",
        "7 -1.675569456 -0.7212884940  0.36034372\n [15,] -1.54128861  0.027507610  1.700066272 -0.9063753860 -0.10836449\n [16,] -1.36941992 -0.124648666 -0.284725525 -0.1157372744  0.80284164\n [17,]  0.67696536  1.514340750 -1.306395177  0.0487604286 -2.17778112\n [18,] -0.15058915  0.218825748 -0.142937112 -0.7053200554 -0.36307128\n [19,]  0.29768016  0.706584465 -1.426160797  1.5865979115 -0.12929702\n [20,] -1.59199005  0.092369653 -1.847766496  0.3934170005 -1.10361065\n               [,6]         [,7]        [,8] ",
        "       [,9]       [,10]\n  [1,] -0.556686043 -0.697151725  1.00440808 -1.25299962 -2.28476259\n  [2,]  0.655408031 -0.112884034  0.84311673  0.17007145  0.60293677\n  [3,] -1.326925417  0.116533850 -0.78348282 -1.11310237  0.28238370\n  [4,] -0.150165496  1.729599964  0.88567159  1.70463910  0.55266138\n  [5,] -0.596622362 -1.151498360  0.93267607 -0.67345942 -1.54226508\n  [6,]  0.895496220 -1.012747978 -1.05989901  0.22848713  0.09372600\n  [7,]  0.199519025  1.926501354 -0.11638338  0.86959709  0.48091012\n  [8,",
        "]  0.158473793 -0.591714509 -0.83048619  0.44386242 -0.10582700\n  [9,]  0.629131429  0.271599746  0.28070211  0.87063994  0.20386413\n [10,]  1.428990285 -0.114692030 -0.06295242 -0.45013377  1.16627540\n [11,]  2.219921864 -1.245845152 -0.67942406  0.72034821 -0.92533431\n [12,]  0.140249394 -0.519829796 -1.30104607  0.83070854  0.77252755\n [13,]  0.239849417  0.217972959 -0.59588845 -0.99717290 -0.25130436\n [14,] -1.326395517  0.147020389 -0.57051723 -0.10643459 -0.07933924\n [15,]  0.913941955 -0.296130507 -",
        "0.17567186 -0.52566655  0.96651798\n [16,] -1.755829348  0.147347057 -0.95610015  1.09634027  0.11926222\n [17,] -0.629202257  0.394147621 -0.33092866 -0.91953793  0.11338235\n [18,]  0.566974911 -0.907163014 -1.23898830  0.11356978 -0.12602440\n [19,] -0.133918184  0.870486447  0.22127279 -0.17458684  0.85303430\n [20,] -2.691176305  0.212844877 -0.84387163 -1.12862749 -1.65252559\n             [,11]       [,12]       [,13]       [,14]        [,15]\n  [1,]  0.46216074 -0.73323724 -0.23290811  0.95530035 -1.433852",
        "790\n  [2,] -0.92907409 -0.09443493 -0.49123587  0.26629083 -1.577966824\n  [3,]  0.49170646  0.59641045 -1.94528526 -0.47663813  2.425253211\n  [4,] -0.67790731 -1.72507974 -0.09831084 -0.03921041  0.600633533\n  [5,] -0.99498351  0.32321399 -2.70337237  0.27922901  0.702817841\n  [6,] -0.59978507 -1.28086305 -0.62982836 -0.40895539  0.337882257\n  [7,] -1.62558227 -0.70633007 -0.31152108 -1.01031568  0.964084362\n  [8,] -0.76605704 -0.45762986 -1.76910890 -1.41419092 -1.653785732\n  [9,]  2.49123580  1.67754805  ",
        "1.46116771  1.34617872  1.859243132\n [10,]  0.03677096 -0.26416993  1.70672067 -0.48693084 -0.749585754\n [11,]  0.61334452  0.80102575  0.64549489  0.10735589 -1.067617371\n [12,] -0.77549880 -1.09731652 -0.67246318 -0.77503780  0.463377213\n [13,] -0.69777595 -0.28684531  0.58863590  0.22787451  0.867481133\n [14,] -0.29370242 -0.13036150  0.97389861 -0.79262261 -2.102847706\n [15,]  0.05979140 -0.08199185 -0.47512425  0.06061360  1.077987116\n [16,]  1.13836059  0.61574089 -0.37071490  0.22540275  0.016162921\n",
        " [17,] -1.28418345 -0.15236022  0.33462980 -0.50315861 -0.812597575\n [18,]  2.14620846  0.53674367  2.06218411  1.39515916  0.646109946\n [19,]  0.59117708  0.03431686 -0.30396191 -1.09321016 -0.531969971\n [20,] -0.07224769  0.05679349 -0.50231730 -1.04306896 -0.055339878\n             [,16]        [,17]       [,18]        [,19]        [,20]\n  [1,]  0.43165264 -1.418487997  1.00926128  1.283753410 -0.351294262\n  [2,]  0.29893611  1.836071618 -0.31911367 -0.914510715  0.311854601\n  [3,] -1.35124549 -0.68234248",
        "6 -0.55855875  0.384796941  0.324238556\n  [4,]  0.12436899 -0.006478716  1.62880094  0.311343992 -1.054009727\n  [5,] -0.26506749  0.732888068 -0.42920067 -0.395639709 -0.443210501\n  [6,] -0.64573027 -0.387742607 -0.53037309  0.768333175  0.723108843\n  [7,]  0.39088684  0.151692788  1.92673353  0.840707157  0.579579574\n  [8,]  1.66512645  2.745720200  1.95264324 -0.545254773  0.850115926\n  [9,]  0.61816146 -1.762252958  0.46759211  0.753462829  0.155106513\n [10,] -1.04879125  2.103074749  0.86439230  0.79924",
        "1133 -0.611843788\n [11,]  0.50902464 -0.688060480 -0.99669545  0.072949489  1.394422051\n [12,] -0.09921915 -0.654185006  1.03398723  0.096321471  0.553621076\n [13,] -0.89082172  0.595522286 -0.72246757 -1.754273357  0.277221770\n [14,]  0.78658353 -1.637806634  0.38088531 -0.182151673  0.524526777\n [15,]  0.14796783  0.904522509  0.17530938  0.454817471  0.066720288\n [16,]  0.60205389 -1.353615175 -0.47397437 -0.489087235  0.567742861\n [17,] -0.07166210 -0.304218869  1.30428222  1.340977983  1.352359886\n [18",
        ",] -0.52831985 -0.354021831 -0.59817486  0.507122622 -1.695432300\n [19,]  0.05092058  1.542962955 -0.95615665  1.095744023  0.311203389\n [20,] -0.91645929 -0.112871470 -0.08432830 -1.270918850  0.467504661\n              [,21]        [,22]        [,23]        [,24]       [,25]\n  [1,] -0.252956090 -1.351914079 -0.693684366 -0.705579869 -0.19646159\n  [2,] -3.083888606 -0.334020617 -0.108751684 -0.445300661  0.23633367\n  [3,] -0.989105314 -0.390279066 -1.485583843  1.473840173 -0.83838748\n  [4,] -0.243791823  0",
        ".880365440 -0.990834131  0.876031974 -1.67298406\n  [5,] -1.199180239 -0.246117849  0.250582763  1.093662558  2.13865740\n  [6,] -1.424490970 -1.271483266 -0.704793519 -2.179736413 -1.94212309\n  [7,]  0.045327302 -1.723719448 -0.802367628 -0.900651726  1.51754046\n  [8,] -1.656786737  0.693696080 -0.887458858  0.537031535 -0.42506579\n  [9,]  0.523323082 -0.543251257  0.237434800 -0.242900176  0.16386551\n [10,] -1.707978313 -0.123342715  0.412640330  1.745223701  0.83797823\n [11,] -0.326288359  1.865824785 -0.1",
        "26789685  1.475465518 -1.28617074\n [12,]  0.343326121  0.368671335 -1.249349928  0.449003329 -1.98999869\n [13,]  0.891364786  0.300630635  0.532162172  0.810548573  1.64811360\n [14,] -1.103143716 -1.220766036 -0.367778663  0.463144691 -0.24538009\n [15,] -1.404692046  0.864140354 -0.399997362  1.052173028  1.41401577\n [16,] -0.917607603 -0.438537153 -2.407648007 -2.420193532 -1.03856469\n [17,] -0.002995535  1.330677987 -0.602338408 -1.046439820 -0.07096225\n [18,]  1.476047636  0.752952084  0.123813282  0.530",
        "496714  1.59969503\n [19,] -0.453118508 -0.779584633 -0.034774142 -0.160229342 -0.46922754\n [20,]  0.354751535 -2.101628984 -0.294432265 -0.737657124  0.79954002\n              [,26]        [,27]        [,28]       [,29]       [,30]\n  [1,] -0.304089308  0.073247206  0.110033541  0.02612589 -0.23290602\n  [2,] -1.406817751  0.466396215  0.595293195 -0.15624693  2.43878711\n  [3,]  1.294566080  0.975440903  0.391803494  1.21241058  0.37561651\n  [4,] -0.036953115  0.393516956 -0.380656883  0.63040117 -0.63913362\n ",
        " [5,] -1.466174763 -0.949207232  1.459347931 -1.28380100 -1.01079852\n  [6,] -1.050631253 -0.979619874 -1.345465047 -0.69780707 -0.50973149\n  [7,]  2.863563775  1.064243779 -0.330567437 -0.12159934 -0.15923770\n  [8,] -0.202949653  1.322939237 -0.957399793  1.23288902  0.85362760\n  [9,] -0.194862524  0.568910372  0.550551795 -0.16656542  0.06285392\n [10,] -0.845902908 -0.744747198 -0.315821765  0.63585351 -2.08121593\n [11,]  1.069330493  0.073371172 -1.139871436  0.66138029  0.98820481\n [12,]  1.171280037  0.",
        "066475875 -0.519304645  0.86163910 -0.50942951\n [13,] -0.919757961  0.817672678 -0.034090150  1.49421210  1.82722539\n [14,] -0.564824679 -0.583198639 -0.657600098 -0.39462512  0.44316110\n [15,] -0.398354193 -0.037259395 -0.363786168 -0.38172280 -1.55825432\n [16,]  0.571131476  0.305054376 -0.691415045  0.73296609  1.11252456\n [17,]  0.276950367 -0.786677323  0.504515076 -0.61826202  1.87966122\n [18,] -0.167649059 -1.689625256 -0.380469023 -1.18045869  0.82399033\n [19,] -0.218230422  2.793297728  0.296410159",
        "  0.38086179  0.85648921\n [20,]  1.127154505  0.287302350  1.310555410  1.28713253  1.15653970\n             [,31]        [,32]        [,33]        [,34]        [,35]\n  [1,] -0.27524441  1.236826859  0.815467301  0.550446499 -0.215738749\n  [2,]  1.01558172 -0.450726857 -1.422574188 -0.362197389 -0.115420373\n  [3,]  0.73400469  1.059176335 -0.610908057  0.809664626 -1.837709034\n  [4,]  0.96868497 -0.976350064 -0.405845225  0.892018655 -1.690927001\n  [5,] -1.03721993  0.104647692 -2.025249275  1.335003746  0.7",
        "66435878\n  [6,] -0.56763535 -0.451875864 -1.270268265 -0.440548890 -3.008756453\n  [7,]  1.22284649  0.563415125 -0.809498077  0.082184002  0.606932675\n  [8,]  0.74359912  0.526519789  1.420093501  1.036066086  1.347891112\n  [9,]  0.66573058  2.483739128  0.623316748  1.164900429 -0.736202889\n [10,]  1.60750816  0.991340799 -1.455657600  0.710428003 -0.496743351\n [11,]  0.14076601  0.327755664  0.012104617  0.189177659  0.230644408\n [12,]  0.32860014 -0.777038511 -1.068836162 -0.189754394 -0.433984314\n [13,]",
        " -1.91895396  0.758467683 -0.286864834 -0.480673940 -0.401249774\n [14,]  0.15009559 -0.999417397 -0.131077265 -0.886410071  1.085767584\n [15,]  0.19335191  0.566075893 -0.813561480  1.028847453  0.556867956\n [16,] -0.01067297  0.072803285  1.054023584 -0.602049802  1.156472693\n [17,] -0.90665577  0.705309184  1.325013518 -1.698599859 -0.472927272\n [18,]  0.15504071 -0.872376786 -0.007859793  1.153123862  0.078761618\n [19,]  0.82931229  1.744521245  0.612130930 -1.124403105 -0.658756592\n [20,]  1.16676706  2",
        ".103442511  0.061955715 -1.235044826  1.051887904\n              [,36]       [,37]       [,38]       [,39]        [,40]\n  [1,]  0.637857013 -0.93047886 -0.02534065  1.34663650  0.699018463\n  [2,]  1.152014389  1.26056837  0.15836922 -1.01089424 -0.827524394\n  [3,]  0.987459723 -0.74967273  0.39929567  2.24284218 -0.178197219\n  [4,] -1.060470086  0.70871780 -1.15107241 -0.52079168 -0.730309343\n  [5,]  2.413206719  0.61808566 -0.08963994 -1.27167497  0.987923991\n  [6,] -1.356900589  1.12959587 -0.10302377 -1.3",
        "3808777 -0.765050725\n  [7,]  0.606419864  0.72510281 -0.53732484 -0.09647945 -0.206052747\n  [8,] -0.085694315 -0.41999129 -0.62842336  0.24965034 -1.386649428\n  [9,]  0.122493516 -0.68330469  0.04324528 -2.98868553  0.974905513\n [10,] -0.493082143 -0.18550834  0.48177611  1.04088180  0.674392682\n [11,] -1.630209746 -1.19907731 -1.47754533  0.09280626 -2.107332674\n [12,] -0.875762950  0.55955181 -0.52458544  0.83008197  0.442523998\n [13,]  1.512141742  0.14531884  0.54678049  1.09498694 -0.209195416\n [14,] -",
        "0.338423066  0.78243587 -0.72991638 -0.17029090  0.190971906\n [15,]  0.133128482  1.23477956 -0.08196365  0.04752826 -0.449620771\n [16,]  0.640838181  1.72297998  1.10116541 -1.57459045 -0.519231860\n [17,]  0.255351811  0.23349664  0.69114611  0.78990835 -3.103840603\n [18,] -0.717429044 -0.02563844 -0.29381504 -0.51144103 -0.271938694\n [19,] -0.342992992 -2.48706186  0.01047010  0.33222371  0.321154619\n [20,] -0.649555672 -0.07446309  0.61295932 -0.68734862 -0.687096915\n              [,41]        [,42]     ",
        "   [,43]       [,44]       [,45]\n  [1,] -0.046506513  0.161795872  1.909954150 -2.15914023 -2.87527791\n  [2,] -1.909402427 -1.718977903 -0.719284446  1.41126448  0.16460709\n  [3,]  0.694620889 -0.188591194 -0.395532813 -0.09965875 -0.49903520\n  [4,] -0.383490318  0.884578372 -0.832193490 -1.27560864  1.38583968\n  [5,] -1.088860626  0.072951624 -0.221922594 -0.17316700 -0.60978613\n  [6,] -0.079342845 -0.068010621 -2.354996028  0.99795561 -1.16420729\n  [7,] -0.835613334  0.324351444 -0.539498551 -1.61808747 -",
        "1.25980035\n  [8,]  0.978953462 -0.098013206 -0.729281245 -1.43701466  1.57697929\n  [9,]  0.487774755 -0.729105707  1.574559211 -0.41909051 -0.86057503\n [10,] -1.298021963  0.409200583  0.771543639  0.60047466 -1.31998070\n [11,] -0.056680516 -0.663752291  0.114019732  0.34951614  0.52179287\n [12,]  0.760440219  0.862965453  1.360770580 -0.06692636  2.54636801\n [13,]  1.005795581  0.270735212  0.683775377 -0.77221257 -0.01053361\n [14,]  0.188691169  1.248353776  0.491340824  1.08855969  0.97360745\n [15,]  0.5",
        "08988351  0.598836867  1.007003717  0.66343717 -0.02151969\n [16,]  1.480524667  0.800313271  1.544416200  1.57269643 -0.54489676\n [17,] -1.745728956 -0.393150835 -0.005631635 -0.36045860  0.09992964\n [18,]  0.904624283 -0.989755016 -0.250777567 -0.17113055  1.98602738\n [19,] -0.548723370 -0.333414985 -1.553563302 -1.82314332  1.48465931\n [20,]  0.617326408 -1.061787233  1.804304411  0.70282379  0.57183823\n              [,46]        [,47]        [,48]       [,49]        [,50]\n  [1,]  0.935886378  0.129435406",
        " -0.477554572  0.43494857  0.153907603\n  [2,]  0.864673402  0.913338411 -0.817490729  0.36978325  1.084621262\n  [3,]  1.202476067  0.420799623 -0.627878796  0.89832377 -0.437268261\n  [4,]  1.081813098 -0.171115789  1.624333917 -1.40534790  2.327890157\n  [5,]  1.733901638  2.463910172  0.007018353  1.65238698  1.294240740\n  [6,] -1.085699903 -0.884280901 -0.481172381 -1.31401301 -0.230902400\n  [7,] -1.143363314  0.304282484 -0.819697934  0.41316819 -0.082343818\n  [8,]  0.313708038 -0.824488631  0.482053888  ",
        "0.14824642 -1.061836391\n  [9,] -0.275890781  0.905470817  0.895111240  0.36618983 -0.109849816\n [10,]  0.003576347 -0.286281093  2.154342777  0.54816049  0.018433307\n [11,] -1.812380800 -0.183659477 -1.806264636 -0.09253825  1.923506725\n [12,]  0.101893462 -1.026223346 -1.241432900 -1.42252663 -1.465838994\n [13,] -1.001766480 -0.043986071  1.364783422  1.08044426 -0.271087404\n [14,]  1.028246896  0.087350438  0.563988955 -0.59501283  0.514053310\n [15,]  0.848806339 -0.195177986 -0.534749179  0.61614608 -0.3",
        "80482946\n [16,] -0.814903457  0.585036865  1.217806745  1.32957158 -0.170545535\n [17,] -2.589052071 -0.826509683 -0.505468612 -0.14208272  0.504131920\n [18,] -1.431800746  1.234692426 -0.286440903 -0.64543174 -0.526480340\n [19,]  1.827411119 -0.879644337 -0.770499546  0.50471495  0.289544743\n [20,] -0.486472173 -1.370167604 -1.681083253 -1.32893815  0.015058965\n [ reached getOption(\"max.print\") -- omitted 80 rows ]\n",
        "> ",
        "library(AdapDiscom)",
        "> ",
        "library(MASS)",
        "> ",
        "> ",
        "# Set parameters",
        "> ",
        "n <- 100        # Training sample size",
        "> ",
        "n.tuning <- 50  # Tuning sample size  ",
        "> ",
        "n.test <- 50    # Test sample size",
        "> ",
        "p <- 50         # Number of variables",
        "> ",
        "pp <- c(20, 15, 15)  # Block sizes (must sum to p)",
        "> ",
        "> ",
        "# Generate block-diagonal covariance matrix",
        "> ",
        "Sigma <- generate.cov(p, example = 2)  # Block diagonal structure",
        "> ",
        "> ",
        "# Generate true beta coefficients",
        "> ",
        "beta.true <- c(rep(2, 10), rep(0, 10), rep(1, 10), rep(0, 5), rep(-1, 10), rep(0, 5))",
        "> ",
        "> ",
        "# Generate training data",
        "> ",
        "X.train <- mvrnorm(n, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.train <- X.train %*% beta.true + rnorm(n)",
        "> ",
        "n1=n2=n3=n4=n%/%4",
        "> ",
        "p1 = pp[1]",
        "> ",
        "p2 = pp[2]",
        "> ",
        "p3 = pp[3]",
        "> ",
        "X.train[(n1 + 1):(n1 + n2), (p1 + p2 + 1):(p1 + p2 + p3)] <- NA",
        "> ",
        "X.train[(n1 + n2 + 1):(n1 + n2 + n3), (p1 + 1):(p1 + p2)] <- NA",
        "> ",
        "X.train[(n1 + n2 + n3 + 1):(n1 + n2 + n3 + n4), (1:p1)] <- NA",
        "> ",
        "> ",
        "# Generate tuning data",
        "> ",
        "X.tuning <- mvrnorm(n.tuning, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.tuning <- X.tuning %*% beta.true + rnorm(n.tuning)",
        "> ",
        "> ",
        "# Generate test data",
        "> ",
        "X.test <- mvrnorm(n.test, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.test <- X.test %*% beta.true + rnorm(n.test)",
        "> ",
        "X.train",
        "              [,1]        [,2]         [,3]        [,4]        [,5]\n  [1,] -0.87116392  1.46270573  0.262430384  1.09850359 -0.05332422\n  [2,] -1.13428644  0.15716838 -0.261185736 -2.02925300 -0.30744734\n  [3,] -0.16606322  0.50411686  0.678502439 -0.45363754 -1.18840546\n  [4,]  0.95252803 -1.98806691 -0.780600088 -1.10320068  0.55410482\n  [5,]  0.18671779  0.76554219 -0.078441102 -0.07053223  0.47390841\n  [6,] -2.16891881  0.60393776  0.833005632  0.63156975 -0.16322061\n  [7,]  0.73641518  0.83987121 -0.00",
        "4147213  2.18447348  0.51684087\n  [8,]  1.18018177  0.05896952 -0.372418600  1.19519719  1.21664607\n  [9,] -0.35262013  1.31115479 -1.039328130  0.50945565  1.78848646\n [10,]  0.58967357 -0.52810070 -1.012426495  0.28414683 -1.01072061\n [11,]  0.39518931 -0.53802842  0.571556879 -0.73597393 -0.65176183\n [12,] -1.10623922  0.61453623 -1.514835803  0.55861613  1.05241042\n [13,] -0.94262181 -2.04768469  0.138329873  0.18605127 -0.86799559\n [14,] -1.55613350 -0.56866123  0.685859372 -1.57373665  1.66000651\n [15",
        ",]  0.88465101  0.93343291 -0.183533838  0.71666256  0.12743241\n [16,]  1.32816471  0.45171402  0.960426805  1.80709051  1.97030041\n [17,]  0.83758287  0.50690242  0.856576555 -0.25919719 -0.37306429\n [18,] -0.76883777 -0.81018690  0.013368712 -1.07145697 -0.19123809\n [19,]  0.26207385 -0.96949126  0.969360912  1.85793764  0.16832234\n [20,] -0.70830000 -0.92112502 -0.246620586  0.35789636 -0.41972133\n              [,6]        [,7]        [,8]        [,9]       [,10]\n  [1,] -1.33258180 -2.32786794  0.9199880",
        "9  0.12485912 -2.56397353\n  [2,]  0.51599297 -1.18417778 -0.24370691  0.30180840  0.94734747\n  [3,]  0.87618150 -0.03191598 -0.19833051 -0.45778560 -0.85839551\n  [4,] -1.51937383 -0.79831838 -0.91829981  0.31902276 -1.90136014\n  [5,]  0.41973764  0.24724490 -0.09559716 -1.02012441  1.56174411\n  [6,]  0.24475471 -0.33846231  1.01572996 -1.28543407 -0.18254645\n  [7,]  1.51410964  0.93277068  0.71039431  1.02146225 -0.17672514\n  [8,]  2.01487097  0.08205318  1.22886052  1.57360539  0.72792947\n  [9,]  1.2799903",
        "6 -1.16372678  0.38439829  0.39228302 -0.33950941\n [10,]  0.46277163 -1.06652486  0.29399923 -0.76227547  0.40854390\n [11,]  1.41416506 -0.19587648 -1.25114536  1.20072271 -0.74893998\n [12,]  0.05914686 -1.57280725 -2.03590681 -1.45044339 -1.55392788\n [13,]  1.34534211 -0.63919058  1.04637977  0.43997602  2.17542235\n [14,] -0.02985471  1.39763046 -0.21281932 -0.11363101 -0.76996159\n [15,]  1.27303234  2.72415662  0.98949459 -0.14343973  0.19930145\n [16,] -1.79895746  0.32232773 -0.33654490 -1.22985979 -0.30",
        "152495\n [17,]  0.25709449 -1.34549197 -0.96417229 -0.99916758  1.67527524\n [18,] -0.19980662 -1.04343365 -0.61078980 -0.28620801 -1.82914094\n [19,] -0.37625128 -0.52368434  1.10085414  0.15839923  1.06639367\n [20,]  0.67963159  0.73292668  1.26695106  0.42304980 -0.14707278\n              [,11]       [,12]        [,13]       [,14]       [,15]\n  [1,] -1.338241679  0.27112120 -0.563141810 -1.89055165  0.81815230\n  [2,] -0.926545402 -0.89341440 -1.277212700  0.06362098  0.08319340\n  [3,] -1.754424384 -1.9401315",
        "2 -0.781851430  0.87835101  0.17837161\n  [4,]  2.008051717  1.26650760  2.818543230 -1.01697203 -0.41124594\n  [5,] -0.242032096 -0.12126988  0.788103539 -0.74638139  0.35863048\n  [6,]  1.420989744 -0.23145550  0.628881109  2.14858344  1.94659622\n  [7,]  0.327767122 -0.48000840  0.514456218 -0.26810415 -0.27435572\n  [8,]  2.662073078  0.64780015  0.744260212  0.32829028  2.93771611\n  [9,] -0.120159609  1.73348527 -1.908669352  0.12703214  0.54566564\n [10,] -0.441744741  1.44095230  1.427663046 -0.02411649 -1",
        ".13813385\n [11,]  0.284939693  2.03470997 -0.849172832  1.03131364 -0.80599670\n [12,]  2.234235873 -0.30988893  1.469865313 -0.37893610  0.58582791\n [13,]  0.049215443  0.26045106 -0.115625879 -0.61408004 -0.31821201\n [14,] -1.126287598  0.64021549  0.713809491  0.56674055  1.40614115\n [15,]  1.342859903  0.01341030  0.563697131 -0.45994962  1.09136724\n [16,]  0.420938528 -0.58103754  0.389752140  0.38077139 -0.91894772\n [17,]  0.775325800  2.18681790 -0.503312853  1.55842870  0.86003350\n [18,] -1.002770576",
        "  0.05937810 -0.789993090  0.15173501 -0.80419666\n [19,] -1.308927071 -0.63044982 -1.098094461 -0.68985283 -0.56130921\n [20,]  0.289804524  1.67751530  0.067640292  1.14002145 -1.60830137\n              [,16]        [,17]       [,18]       [,19]        [,20]\n  [1,] -0.140813244  1.647638459 -1.65321500 -0.68036817 -0.784789072\n  [2,] -0.919203182  0.142542398  0.52235512 -0.60364194  0.345304543\n  [3,] -1.066730662  2.276936103 -0.52479781  0.78318964 -0.507150395\n  [4,] -0.899031428 -1.921787990 -2.52065039",
        " -1.08041799 -0.226568383\n  [5,]  0.146648963  0.407723424 -0.86990668  1.01975139 -0.952525141\n  [6,] -0.713257629 -0.283125737 -0.26730833 -0.14134800  0.840867624\n  [7,] -0.240234597 -2.054258685 -1.25766937  0.50642830 -0.588697620\n  [8,] -0.115567826  0.451961252  0.27832699 -0.25769312 -1.020481695\n  [9,] -0.262955058 -0.252308454  0.73601767  1.18739639  0.303154775\n [10,]  1.618840182 -1.630888700 -1.84719755 -1.51997968 -2.454215329\n [11,] -0.508705066 -0.472435406 -1.15194801  0.60176046 -0.147494",
        "458\n [12,]  0.575048437 -0.121255712 -0.56083934 -0.43269258  0.318933158\n [13,] -0.325108149 -0.195293872 -0.41513143  1.82448415  1.254319848\n [14,]  0.733243267  1.863515805 -1.81500978  0.38209681 -0.995348445\n [15,]  0.919018048 -0.681055977 -0.05275165 -1.34670947 -0.270290021\n [16,]  2.015105195  1.091440915  2.22516733  0.91550752  1.564671341\n [17,]  0.540693497  1.409100404  0.02959157 -0.33995120 -1.876342162\n [18,]  0.186082567  0.096503770 -0.12642184  0.12583994  0.023577035\n [19,]  1.25831549",
        "9  0.750945894 -0.80614589  0.40196558  0.721497587\n [20,]  0.907882351  0.392717529  0.01182301  0.02943868  2.725336025\n              [,21]         [,22]        [,23]       [,24]         [,25]\n  [1,] -0.703882925 -1.2008673670 -0.366298576 -0.77960205  5.139387e-01\n  [2,]  0.996392885 -0.3338934924 -0.923851034  1.12756111  2.707450e-02\n  [3,] -0.776437723  1.1470931758 -1.249493873  0.10960175 -1.592822e+00\n  [4,]  1.141773181  0.2190495280 -0.367044141  0.35973495 -3.173173e-01\n  [5,] -0.009147827  0.06",
        "87625523 -1.258309061 -0.63089220  1.454754e+00\n  [6,] -0.919302369  0.4991651193 -0.706915088  0.74141521 -5.383768e-01\n  [7,]  2.207777198  0.6811479631  0.854552957 -2.48548184  9.648185e-02\n  [8,]  1.195927119  0.0125713912 -0.127554584  3.70093992  9.367760e-01\n  [9,]  0.061062517 -1.7338304729 -0.212857469 -1.88071437  7.005255e-01\n [10,]  1.027652719  0.5007546119  0.721830331  1.69553094  1.619415e+00\n [11,] -2.157412131 -2.3803156895 -0.325950471  0.36357001 -1.203172e+00\n [12,]  0.598953643 -0.927",
        "0511589 -0.836887378 -0.72052949 -4.208533e-01\n [13,]  0.182990126 -1.1116506995 -0.630579433 -2.95549718  7.386945e-02\n [14,] -0.422990988 -0.9483526754 -0.146398650 -1.68043220  5.149700e-01\n [15,] -1.952895493 -1.5440131835 -0.751021871 -0.68796219  2.474722e-01\n [16,] -1.680814350  0.5913074687 -1.372600396 -1.19578427 -2.247738e+00\n [17,] -0.123142577  0.1019538136  1.559961346  0.19343755  5.480636e-01\n [18,] -1.581108194  2.6820658178  1.166738594  2.42779569 -4.246662e-01\n [19,]  0.631313272  0.7588",
        "694794  1.134540970  1.37723285  5.737745e-01\n [20,]  0.485708223 -0.5882540060 -0.682610652  0.79432981 -1.563538e+00\n             [,26]       [,27]        [,28]         [,29]       [,30]\n  [1,] -0.28055042 -0.69199004  0.027286852 -1.2473046158  0.43121875\n  [2,] -0.80237171 -0.74886154 -2.559203540  0.5073056547  0.26568555\n  [3,]  0.31176791  0.56610301 -1.336364282  0.1867649084  2.33359751\n  [4,]  0.35731127  0.33193357 -0.496210449  0.1983321517 -1.23222363\n  [5,] -2.15587172 -1.66683194 -1.683061260",
        " -1.5319833493 -2.16512263\n  [6,]  1.66153741 -2.22643853 -0.002156471 -1.1556575458 -0.18643019\n  [7,]  0.89084855 -0.86353393 -0.202764635 -0.4073164419 -1.94056006\n  [8,] -0.41576261 -2.21298336  0.085854634 -0.7605882260 -1.93121235\n  [9,] -0.39154765 -0.49834227  1.025501061  0.0771292214 -0.10405877\n [10,]  1.01957156  0.92370997 -0.604388532  0.1565319090  0.63008623\n [11,]  0.50731899  0.02083354 -0.093884432  0.2290147076 -0.53931190\n [12,]  2.27211912  0.81490029 -0.528609628  0.3151730983  0.9477",
        "6546\n [13,]  0.33390907  0.09059509 -2.284670726  0.1661652268  0.07605055\n [14,]  1.03510257  0.93457831  0.151159875 -0.0255603816 -0.12417530\n [15,] -1.21725765 -1.65297596 -0.294642219 -0.2156076291  0.33073587\n [16,] -0.06332693 -1.53988769  0.906724197 -0.8129144318  0.52499220\n [17,] -0.14568043  0.21993601 -1.138135607 -0.6530057031  0.83272084\n [18,] -0.06421627  1.08156517  0.191969837  1.3958818263 -1.24391008\n [19,] -1.23546493  1.40426471 -0.091928084  0.6851594444 -1.05165118\n [20,]  0.3604491",
        "9 -0.18416095  0.491866724 -0.4423822412 -1.98182310\n             [,31]       [,32]         [,33]       [,34]        [,35]\n  [1,] -0.26149583  0.80690547  1.726432e+00  2.21577816  2.755332848\n  [2,]  1.11530040  0.47412673  1.559828e-01 -0.79106088  1.728092799\n  [3,] -0.44516046  0.90273802  1.218190e+00  0.61191159  0.996044815\n  [4,]  0.51833404 -0.58635486 -9.520070e-01 -0.74550598 -0.063863998\n  [5,]  1.58321730  0.22980650 -1.867151e-01  0.79209060 -0.748463370\n  [6,]  0.07450911  0.08944433  2.03986",
        "3e-01  0.73057918  0.940615072\n  [7,]  0.34521380 -0.50331833 -5.292685e-01 -1.15724477  0.559452222\n  [8,]  0.96208046  0.33920323  1.812789e+00 -0.76546874  0.110146205\n  [9,]  0.48911403  1.63258938  3.168925e-01 -0.81484953  1.947343971\n [10,] -1.92932176  0.74074449 -7.222498e-01 -0.28924472 -0.418950579\n [11,]  1.43788057  0.32386526 -2.445449e-01  0.83267610  0.056028078\n [12,] -1.69017293 -0.72871715 -1.293911e+00 -0.41914597 -0.903131183\n [13,] -0.12632562  1.33689217  1.187978e+00 -1.02694151  1.5",
        "25610791\n [14,]  1.30445382 -2.58442856  1.295279e+00  0.76598530  0.560437085\n [15,]  1.56711709  1.55903928  4.651953e-01  0.90759672  0.058505975\n [16,] -0.20955878  1.34297389 -1.555009e+00 -1.58578307 -0.513510530\n [17,] -1.94120788  0.31593873 -8.867900e-01 -1.98466004 -1.266387375\n [18,]  1.33572940  2.00461613 -4.586503e-01  0.76220298  0.589211437\n [19,] -1.23851149 -0.11336939 -1.145127e+00  0.03504312  1.361137612\n [20,]  1.83597615  0.35363880  9.092683e-01 -0.46881373 -0.697246915\n             ",
        " [,36]       [,37]        [,38]       [,39]       [,40]\n  [1,] -0.724698484 -1.42138759  0.080853006 -1.73898808 -0.17285082\n  [2,] -0.385173507  0.36423116  0.451863582 -0.31874925  0.41080496\n  [3,]  0.432940439  1.79852416  1.940856933  1.60249992  0.99086764\n  [4,]  1.249035500 -0.46999966  0.841480339  1.81038523 -0.15608495\n  [5,] -0.287514191  0.13016423 -0.797200613 -1.53233048  0.80436589\n  [6,] -0.247533786 -0.28128462  0.618619592  1.51527726 -0.19629683\n  [7,]  2.148460604 -2.16732975  0.1181812",
        "61  1.57120439  0.72905102\n  [8,]  0.186737499  1.04060849 -0.513925760 -0.24922565  1.51040580\n  [9,]  0.474178967  0.21906679 -1.037149114  0.66068376 -1.71349964\n [10,] -0.655972089  0.40678647  0.219676530 -0.07807643  0.64018339\n [11,]  0.055109013 -1.08400589 -0.184193721 -0.60567086 -0.74896910\n [12,]  1.782781875  0.78984545  1.120854241  1.24071338  0.14300093\n [13,]  0.078669182 -1.18738631  0.054474771  0.77037213 -2.66793771\n [14,]  0.274731368  0.77620810  0.016606388  0.02741107 -2.15498778\n [",
        "15,]  1.764407223  1.53036662  3.024842333 -0.13044191  1.47987725\n [16,] -0.884258634 -0.68942192 -0.769327154 -0.60847885  1.29813219\n [17,] -0.190697290 -0.24001660 -0.454465569 -0.19118376 -0.14763163\n [18,]  0.315043665  1.17189181  0.354606273 -0.75549689  0.75236665\n [19,]  0.003867884 -0.47515270 -1.025365098 -1.24967512  1.14316167\n [20,] -0.995296879 -0.12797314 -0.845591675  0.39824412  1.05348803\n              [,41]        [,42]        [,43]       [,44]       [,45]\n  [1,] -1.109579852 -0.4506396",
        "72 -1.337531734 -0.51777773 -1.63426649\n  [2,] -0.439339737  0.821674482  0.353945161  0.07315068  1.22797952\n  [3,] -0.006744977 -1.402146817 -0.634834103  0.24340142 -0.16410018\n  [4,]  0.463626967  0.617591798 -1.040337188 -1.83809674  0.46809940\n  [5,]  0.032660588 -0.399922290 -1.348587793  0.10607575  0.34941424\n  [6,] -0.029139331  0.211066577  1.250583465  0.56973809  0.98042726\n  [7,] -0.831757477  0.817545041  0.670741513 -1.05178469 -2.17324150\n  [8,] -0.117501914 -0.135736477 -1.296431736 -0.887",
        "98562 -1.05813343\n  [9,]  0.066853449 -0.780297553 -1.260993601 -1.59638720 -0.31969389\n [10,] -0.784971753 -0.829635432  0.091415858 -0.03705319 -0.71384076\n [11,] -1.305035279  1.583573014  0.714489506  0.29571417 -0.26916290\n [12,]  1.114168554  1.029123601  1.278855695 -0.20119028  1.51597572\n [13,] -0.445735594  0.614250132  0.767062548 -0.26099917 -0.56301696\n [14,] -0.490245401 -0.073023179  0.689549391 -0.65026374  0.34313761\n [15,] -3.015534297 -1.430887278  0.932079145  0.38569422  0.72152882\n [16",
        ",] -1.617334075  0.205670356 -1.482322747  0.47548823  0.22048475\n [17,]  0.059199509  1.287688551 -0.260774011  0.91253005 -1.27528369\n [18,] -0.623734219 -0.201768899 -1.681865383  0.45652827 -1.04994955\n [19,] -2.008437536  0.026671777 -0.397041954  1.27746565 -0.09692448\n [20,] -0.800591746  0.741234267  1.968546549 -1.29790089  1.32099514\n              [,46]       [,47]       [,48]        [,49]       [,50]\n  [1,]  0.951075734 -0.54274473  2.00259868  0.863613952  0.77273072\n  [2,]  1.044708880 -0.43824",
        "835  0.56277728 -1.578124856  0.56491041\n  [3,]  0.093751610  3.37559080 -1.84162928 -0.105149060  0.09777671\n  [4,]  0.126887798 -0.51368383  1.15171729  0.613402065  0.75047428\n  [5,] -0.601003750  0.58056638 -0.58052794  0.182007499  2.00100366\n  [6,] -0.120103077 -1.48784354 -0.95859145  1.725021626 -1.17297138\n  [7,] -0.521714234  1.03550844  1.68124939  2.085729724  0.07943552\n  [8,]  0.732566562  0.72803297  0.04240742  0.661219237  0.37710023\n  [9,] -0.148209117  0.01113136 -0.89167596  0.425950329 ",
        " 0.16518819\n [10,] -0.708324264 -0.02211543  1.06225503  1.011147220  0.05583869\n [11,] -1.274105871 -0.48825736 -0.35821355  0.123038608 -0.85038928\n [12,] -1.573965610 -0.16932115 -0.04186072 -0.341768228 -0.26790376\n [13,] -0.021800361  1.47164048 -0.48505945 -0.684134244 -0.16336854\n [14,] -0.920462122  1.34483133  0.39558966  0.380113892 -0.70531183\n [15,]  0.418913889 -1.33237581 -0.66160912  0.219692979 -0.23849047\n [16,] -0.777935986 -0.51442622  0.49730615  0.917858127 -0.56998967\n [17,] -1.5311944",
        "14  0.99320263  0.83771226  0.132603746 -1.01295809\n [18,] -0.537298040 -0.02045102 -1.78555007  0.659175955  0.00589576\n [19,] -2.049107606  0.84583200 -0.75438395  0.672941726 -1.05138362\n [20,]  0.627429519 -0.54189500  1.23514756 -1.392147538 -0.65478873\n [ reached getOption(\"max.print\") -- omitted 80 rows ]\n",
        "> ",
        "View(X.train)",
        "> ",
        "library(AdapDiscom)",
        "> ",
        "library(MASS)",
        "> ",
        "> ",
        "# Set parameters",
        "> ",
        "n <- 100        # Training sample size",
        "> ",
        "n.tuning <- 50  # Tuning sample size  ",
        "> ",
        "n.test <- 50    # Test sample size",
        "> ",
        "p <- 50         # Number of variables",
        "> ",
        "pp <- c(20, 15, 15)  # Block sizes (must sum to p)",
        "> ",
        "> ",
        "# Generate block-diagonal covariance matrix",
        "> ",
        "Sigma <- generate.cov(p, example = 2)  # Block diagonal structure",
        "> ",
        "> ",
        "# Generate true beta coefficients",
        "> ",
        "beta.true <- c(rep(2, 10), rep(0, 10), rep(1, 10), rep(0, 5), rep(-1, 10), rep(0, 5))",
        "> ",
        "> ",
        "# Generate training data",
        "> ",
        "X.train <- mvrnorm(n, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.train <- X.train %*% beta.true + rnorm(n)",
        "> ",
        "n1=n2=n3=n4=n%/%4",
        "> ",
        "p1 = pp[1]",
        "> ",
        "p2 = pp[2]",
        "> ",
        "p3 = pp[3]",
        "> ",
        "X.train[(n1 + 1):(n1 + n2), (p1 + p2 + 1):(p1 + p2 + p3)] <- NA",
        "> ",
        "X.train[(n1 + n2 + 1):(n1 + n2 + n3), (p1 + 1):(p1 + p2)] <- NA",
        "> ",
        "X.train[(n1 + n2 + n3 + 1):(n1 + n2 + n3 + n4), (1:p1)] <- NA",
        "> ",
        "> ",
        "# Generate tuning data",
        "> ",
        "X.tuning <- mvrnorm(n.tuning, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.tuning <- X.tuning %*% beta.true + rnorm(n.tuning)",
        "> ",
        "> ",
        "# Generate test data",
        "> ",
        "X.test <- mvrnorm(n.test, mu = rep(0, p), Sigma = Sigma)",
        "> ",
        "y.test <- X.test %*% beta.true + rnorm(n.test)",
        "> ",
        "# Run AdapDiscom with default parameters",
        "> ",
        "result <- adapdiscom(",
        "+ ",
        "  beta = beta.true,      # True coefficients (optional, for evaluation)",
        "+ ",
        "  x = X.train,          # Training data",
        "+ ",
        "  y = y.train,          # Training response",
        "+ ",
        "  x.tuning = X.tuning,  # Tuning data",
        "+ ",
        "  y.tuning = y.tuning,  # Tuning response",
        "+ ",
        "  x.test = X.test,      # Test data",
        "+ ",
        "  y.test = y.test,      # Test response",
        "+ ",
        "  nlambda = 20,         # Number of lambda values",
        "+ ",
        "  nalpha = 10,          # Number of alpha values",
        "+ ",
        "  pp = pp,              # Block sizes",
        "+ ",
        "  robust = 0,           # Classical estimation",
        "+ ",
        "  standardize = TRUE,   # Standardize data",
        "+ ",
        "  itcp = TRUE          # Include intercept",
        "+ ",
        ")",
        "Error in if (lambda.min.ratio <= 0 | lambda.min.ratio > 1 | is.null(lambda.min.ratio)) { : \n  argument is of length zero\n",
        "> ",
        "#'   \\item{a1}{The vector of estimated beta coefficients for the final model.}",
        "> ",
        "#'   \\item{select}{The number of non-zero coefficients, representing the number of selected variables.}",
        "> ",
        "#'   \\item{xtx}{The final regularized covariance matrix used to fit the optimal model.}",
        "> ",
        "#'   \\item{fpr}{The False Positive Rate (FPR) if the true beta is provided. It measures the proportion of irrelevant variables incorrectly selected.}",
        "> ",
        "#'   \\item{fnr}{The False Negative Rate (FNR) if the true beta is provided. It measures the proportion of relevant variables incorrectly excluded.}",
        "> ",
        "#'   \\item{lambda.all}{The complete vector of all lambda values tested during cross-validation.}",
        "> ",
        "#'   \\item{beta.cov.lambda.max}{The estimated beta coefficients using the maximum lambda value.}",
        "> ",
        "#'   \\item{time}{The total execution time of the function in seconds.}",
        "> ",
        "#' }",
        "> ",
        "#' @export",
        "> ",
        "adapdiscom <- function(beta, x, y, x.tuning, y.tuning, x.test, y.test, nlambda, nalpha, pp, ",
        "+ ",
        "                       robust = 0, standardize = TRUE, itcp = TRUE, lambda.min.ratio = NULL, ",
        "+ ",
        "                       k.value = 1.5) {",
        "+ ",
        "  ",
        "+ ",
        "  x_std = standardize_x(as.matrix(x), robust = robust, k.value = k.value)",
        "+ ",
        "  xm <- x_std$x.mean",
        "+ ",
        "  xs <- x_std$x.sd",
        "+ ",
        "  if (standardize) {",
        "+ ",
        "    x <- x_std$x",
        "+ ",
        "    x.tuning <- fit_standardize_x(x.tuning, xm, xs)",
        "+ ",
        "    x.test <- fit_standardize_x(x.test, xm, xs)",
        "+ ",
        "  }",
        "+ ",
        "  ",
        "+ ",
        "  start_time <- proc.time()",
        "+ ",
        "  ",
        "+ ",
        "  n <- dim(x)[1]",
        "+ ",
        "  p <- dim(x)[2]",
        "+ ",
        "  n.tuning <- dim(x.tuning)[1]",
        "+ ",
        "  n.test <- dim(x.test)[1]",
        "+ ",
        "  n_blocks <- length(pp)",
        "+ ",
        "  ",
        "+ ",
        "  alpha.all <- 10^seq(10^(-10), -3, length = nalpha)",
        "+ ",
        "  ",
        "+ ",
        "  lmax <- lambda_max(x, y, Methode = \"discom\", robust = robust)",
        "+ ",
        "  nobs <- dim(na.omit(x))[1]",
        "+ ",
        "  if(lambda.min.ratio <=0|lambda.min.ratio >1|is.null(lambda.min.ratio)){",
        "+ ",
        "    lambda.min.ratio <- ifelse(nobs < p, 0.01, 1e-04)",
        "+ ",
        "  }",
        "+ ",
        "  ",
        "+ ",
        "  lmin <- lmax * lambda.min.ratio",
        "+ ",
        "  lambda.all <- exp(seq(log(lmax), log(lmin), length.out = nlambda))",
        "+ ",
        "  ",
        "+ ",
        "  # Création d'un tableau multidimensionnel pour les erreurs",
        "+ ",
        "  dim_array <- rep(nalpha, n_blocks + 1)",
        "+ ",
        "  dim_array <- c(dim_array, nlambda)",
        "+ ",
        "  DISCOM.tun.error <- array(NA, dim = dim_array)",
        "+ ",
        "  ",
        "+ ",
        "  xtx.raw <- compute.xtx(x, robust = robust, k_value = k.value)",
        "+ ",
        "  xty <- compute.xty(x, y, robust = robust, k_value = k.value)",
        "+ ",
        "  ",
        "+ ",
        "  # Création des indices pour les sous-matrices",
        "+ ",
        "  indices <- get_block_indices(pp)",
        "+ ",
        "  ",
        "+ ",
        "  # Création des sous-matrices individuelles",
        "+ ",
        "  xtx.raw.blocks <- list()",
        "+ ",
        "  shrink.targets <- numeric(n_blocks)",
        "+ ",
        "  ",
        "+ ",
        "  for (i in 1:n_blocks) {",
        "+ ",
        "    idx_range <- indices$starts[i]:indices$ends[i]",
        "+ ",
        "    xtx.raw.blocks[[i]] <- xtx.raw[idx_range, idx_range]",
        "+ ",
        "    shrink.targets[i] <- sum(diag(xtx.raw.blocks[[i]]))/p",
        "+ ",
        "  }",
        "+ ",
        "  ",
        "+ ",
        "  # Création de la matrice bloc-diagonale initiale",
        "+ ",
        "  xtx.raw.I <- as.matrix(do.call(Matrix::bdiag, xtx.raw.blocks))",
        "+ ",
        "  ",
        "+ ",
        "  # Calcul de xtx.raw.C",
        "+ ",
        "  xtx.raw.C <- xtx.raw - xtx.raw.I",
        "+ ",
        "  ",
        "+ ",
        "  # Calcul du shrink.target global",
        "+ ",
        "  shrink.target <- sum(diag(xtx.raw))/p",
        "+ ",
        "  ",
        "+ ",
        "  # Créer des indices pour les boucles imbriquées",
        "+ ",
        "  alpha_indices <- expand.grid(replicate(n_blocks + 1, 1:nalpha, simplify = FALSE))",
        "+ ",
        "  ",
        "+ ",
        "  # Boucle sur toutes les combinaisons d'indices alpha",
        "+ ",
        "  for (row in 1:nrow(alpha_indices)) {",
        "+ ",
        "    # Extraire les valeurs alpha actuelles",
        "+ ",
        "    current_alphas <- alpha.all[as.numeric(alpha_indices[row, ])]",
        "+ ",
        "    ",
        "+ ",
        "    # Les n_blocks premières alphas sont pour les blocs diagonaux",
        "+ ",
        "    block_alphas <- current_alphas[1:n_blocks]",
        "+ ",
        "    ",
        "+ ",
        "    # Le dernier alpha est pour xtx.raw.C",
        "+ ",
        "    alpha_non_diag <- current_alphas[n_blocks + 1]",
        "+ ",
        "    ",
        "+ ",
        "    # Calcul du shrink.target pondéré",
        "+ ",
        "    weighted_targets <- 0",
        "+ ",
        "    weight_sum <- 0",
        "+ ",
        "    for (i in 1:n_blocks) {",
        "+ ",
        "      weighted_targets <- weighted_targets + ((1-block_alphas[i])^2) * shrink.targets[i]",
        "+ ",
        "      weight_sum <- weight_sum + (1-block_alphas[i])^2",
        "+ ",
        "    }",
        "+ ",
        "    shrink.target_weighted <- weighted_targets / weight_sum",
        "+ ",
        "    ",
        "+ ",
        "    # Construction de la matrice bloc-diagonale avec les alphas appliqués",
        "+ ",
        "    scaled_blocks <- list()",
        "+ ",
        "    for (i in 1:n_blocks) {",
        "+ ",
        "      scaled_blocks[[i]] <- block_alphas[i] * xtx.raw.blocks[[i]]",
        "+ ",
        "    }",
        "+ ",
        "    xtx.raw.I_scaled <- as.matrix(do.call(Matrix::bdiag, scaled_blocks))",
        "+ ",
        "    ",
        "+ ",
        "    # Construction de la matrice finale",
        "+ ",
        "    xtx <- xtx.raw.I_scaled + alpha_non_diag * xtx.raw.C + ",
        "+ ",
        "           (n_blocks - sum(block_alphas)) * shrink.target_weighted * diag(p)",
        "+ ",
        "    ",
        "+ ",
        "    # Vérification de la positivité",
        "+ ",
        "    if (min(eigen(xtx, only.values = TRUE)$values) < 0) {",
        "+ ",
        "      # Remplir avec 10^8 pour cette combinaison d'alphas et tous les lambdas",
        "+ ",
        "      idx <- as.list(as.numeric(alpha_indices[row, ]))",
        "+ ",
        "      idx_str <- paste(paste(idx, collapse = \",\"), \",\", sep = \"\")",
        "+ ",
        "      eval(parse(text = paste(\"DISCOM.tun.error[\", idx_str, \"] = 10^8\", sep = \"\")))",
        "+ ",
        "    } else {",
        "+ ",
        "      # Calcul des erreurs pour chaque lambda",
        "+ ",
        "      beta.initial <- rep(0, p)",
        "+ ",
        "      for (k in 1:nlambda) {",
        "+ ",
        "        beta.cov <- as.vector(scout::crossProdLasso(xtx, xty, lambda.all[k], ",
        "+ ",
        "                                                     beta.init = beta.initial)$beta)",
        "+ ",
        "        beta.initial <- beta.cov",
        "+ ",
        "        intercept <- ifelse(itcp, mean(y) - sum(beta.cov * (xm/xs)), 0)",
        "+ ",
        "        DISCOM.tun.values <- as.vector(as.matrix(x.tuning) %*% beta.cov) + intercept",
        "+ ",
        "        ",
        "+ ",
        "        # Indexer correctement le tableau multidimensionnel",
        "+ ",
        "        idx <- c(as.numeric(alpha_indices[row, ]), k)",
        "+ ",
        "        idx_str <- paste(paste(idx, collapse = \",\"), sep = \"\")",
        "+ ",
        "        eval(parse(text = paste(\"DISCOM.tun.error[\", idx_str, \"] = mean((y.tuning-DISCOM.tun.values)^2)\", sep = \"\")))",
        "+ ",
        "      }",
        "+ ",
        "    }",
        "+ ",
        "  }",
        "+ ",
        "  ",
        "+ ",
        "  # Trouver les paramètres optimaux",
        "+ ",
        "  opt.index <- as.vector(which(DISCOM.tun.error == min(DISCOM.tun.error), arr.ind = TRUE)[1, ])",
        "+ ",
        "  train.error <- min(DISCOM.tun.error)",
        "+ ",
        "  ",
        "+ ",
        "  # Extraire les valeurs alpha optimales",
        "+ ",
        "  opt.alphas <- alpha.all[opt.index[1:(n_blocks+1)]]",
        "+ ",
        "  block_alphas_opt <- opt.alphas[1:n_blocks]",
        "+ ",
        "  alpha_non_diag_opt <- opt.alphas[n_blocks+1]",
        "+ ",
        "  ",
        "+ ",
        "  # Extraire le lambda optimal",
        "+ ",
        "  opt.lambda <- lambda.all[opt.index[n_blocks+2]]",
        "+ ",
        "  ",
        "+ ",
        "  # Recalcul du shrink.target pondéré avec les alphas optimaux",
        "+ ",
        "  weighted_targets <- 0",
        "+ ",
        "  weight_sum <- 0",
        "+ ",
        "  for (i in 1:n_blocks) {",
        "+ ",
        "    weighted_targets <- weighted_targets + ((1-block_alphas_opt[i])^2) * shrink.targets[i]",
        "+ ",
        "    weight_sum <- weight_sum + (1-block_alphas_opt[i])^2",
        "+ ",
        "  }",
        "+ ",
        "  shrink.target_opt <- weighted_targets / weight_sum",
        "+ ",
        "  ",
        "+ ",
        "  # Construction de la matrice bloc-diagonale optimale",
        "+ ",
        "  scaled_blocks_opt <- list()",
        "+ ",
        "  for (i in 1:n_blocks) {",
        "+ ",
        "    scaled_blocks_opt[[i]] <- block_alphas_opt[i] * xtx.raw.blocks[[i]]",
        "+ ",
        "  }",
        "+ ",
        "  xtx.raw.I_opt <- as.matrix(do.call(Matrix::bdiag, scaled_blocks_opt))",
        "+ ",
        "  ",
        "+ ",
        "  # Construction de la matrice finale optimale",
        "+ ",
        "  xtx_opt <- xtx.raw.I_opt + alpha_non_diag_opt * xtx.raw.C + ",
        "+ ",
        "             (n_blocks - sum(block_alphas_opt)) * shrink.target_opt * diag(p)",
        "+ ",
        "  ",
        "+ ",
        "  # Calcul du beta optimal",
        "+ ",
        "  beta.cov <- as.vector(scout::crossProdLasso(xtx_opt, xty, opt.lambda)$beta)",
        "+ ",
        "  beta.cov.lambda.max <- as.vector(scout::crossProdLasso(xtx_opt, xty, lmax)$beta)",
        "+ ",
        "  intercept <- ifelse(itcp, mean(y) - sum(beta.cov * (xm/xs)), 0)",
        "+ ",
        "  ",
        "+ ",
        "  # Prédiction sur l'ensemble de test",
        "+ ",
        "  predict.test.values <- as.vector(x.test %*% beta.cov) + intercept",
        "+ ",
        "  ",
        "+ ",
        "  # Calcul des métriques de performance",
        "+ ",
        "  DISCOM.test.error <- mean((y.test - predict.test.values)^2)",
        "+ ",
        "  select <- sum(as.vector(as.integer(beta.cov != 0)))",
        "+ ",
        "  ",
        "+ ",
        "  if (!is.null(beta)) {",
        "+ ",
        "    DISCOM.fpr <- sum((beta == 0) & (beta.cov != 0))/sum(beta == 0)",
        "+ ",
        "    DISCOM.fnr <- sum((beta != 0) & (beta.cov == 0))/sum(beta != 0)",
        "+ ",
        "    DISCOM.est.error <- sqrt(sum((beta.cov - beta)^2))",
        "+ ",
        "  } else {",
        "+ ",
        "    DISCOM.fpr <- NA",
        "+ ",
        "    DISCOM.fnr <- NA",
        "+ ",
        "    DISCOM.est.error <- NA",
        "+ ",
        "  }",
        "+ ",
        "  ",
        "+ ",
        "  R2 <- cor(predict.test.values, y.test)^2",
        "+ ",
        "  ",
        "+ ",
        "  end_time <- proc.time()",
        "+ ",
        "  time_taken <- end_time - start_time",
        "+ ",
        "  ",
        "+ ",
        "  # Préparation du résultat",
        "+ ",
        "  a <- list(",
        "+ ",
        "    'err' = DISCOM.tun.error, ",
        "+ ",
        "    'est.error' = DISCOM.est.error, ",
        "+ ",
        "    'lambda' = opt.lambda, ",
        "+ ",
        "    'alpha' = c(block_alphas_opt, alpha_non_diag_opt), ",
        "+ ",
        "    'train.error' = train.error, ",
        "+ ",
        "    'test.error' = DISCOM.test.error,",
        "+ ",
        "    'y.pred' = predict.test.values,",
        "+ ",
        "    'R2' = R2,",
        "+ ",
        "    'a0' = intercept, ",
        "+ ",
        "    'a1' = beta.cov, ",
        "+ ",
        "    'select' = select, ",
        "+ ",
        "    'xtx' = xtx_opt, ",
        "+ ",
        "    'fpr' = DISCOM.fpr, ",
        "+ ",
        "    'lambda.all' = lambda.all,",
        "+ ",
        "    'beta.cov.lambda.max' = beta.cov.lambda.max,",
        "+ ",
        "    'fnr' = DISCOM.fnr,",
        "+ ",
        "    \"time\" = as.numeric(time_taken[3])",
        "+ ",
        "  )",
        "+ ",
        "  ",
        "+ ",
        "  return(a)",
        "+ ",
        "}",
        "> ",
        "adapdiscom",
        "function(beta, x, y, x.tuning, y.tuning, x.test, y.test, nlambda, nalpha, pp, \n                       robust = 0, standardize = TRUE, itcp = TRUE, lambda.min.ratio = NULL, \n                       k.value = 1.5) {\n  \n  x_std = standardize_x(as.matrix(x), robust = robust, k.value = k.value)\n  xm <- x_std$x.mean\n  xs <- x_std$x.sd\n  if (standardize) {\n    x <- x_std$x\n    x.tuning <- fit_standardize_x(x.tuning, xm, xs)\n    x.test <- fit_standardize_x(x.test, xm, xs)\n  }\n  \n  start_time <- proc.time()\n  \n  n <-",
        " dim(x)[1]\n  p <- dim(x)[2]\n  n.tuning <- dim(x.tuning)[1]\n  n.test <- dim(x.test)[1]\n  n_blocks <- length(pp)\n  \n  alpha.all <- 10^seq(10^(-10), -3, length = nalpha)\n  \n  lmax <- lambda_max(x, y, Methode = \"discom\", robust = robust)\n  nobs <- dim(na.omit(x))[1]\n  if(lambda.min.ratio <=0|lambda.min.ratio >1|is.null(lambda.min.ratio)){\n    lambda.min.ratio <- ifelse(nobs < p, 0.01, 1e-04)\n  }\n  \n  lmin <- lmax * lambda.min.ratio\n  lambda.all <- exp(seq(log(lmax), log(lmin), length.out = nlambda))\n  \n  # Cré",
        "ation d'un tableau multidimensionnel pour les erreurs\n  dim_array <- rep(nalpha, n_blocks + 1)\n  dim_array <- c(dim_array, nlambda)\n  DISCOM.tun.error <- array(NA, dim = dim_array)\n  \n  xtx.raw <- compute.xtx(x, robust = robust, k_value = k.value)\n  xty <- compute.xty(x, y, robust = robust, k_value = k.value)\n  \n  # Création des indices pour les sous-matrices\n  indices <- get_block_indices(pp)\n  \n  # Création des sous-matrices individuelles\n  xtx.raw.blocks <- list()\n  shrink.targets <- numeric(n_blocks)\n",
        "  \n  for (i in 1:n_blocks) {\n    idx_range <- indices$starts[i]:indices$ends[i]\n    xtx.raw.blocks[[i]] <- xtx.raw[idx_range, idx_range]\n    shrink.targets[i] <- sum(diag(xtx.raw.blocks[[i]]))/p\n  }\n  \n  # Création de la matrice bloc-diagonale initiale\n  xtx.raw.I <- as.matrix(do.call(Matrix::bdiag, xtx.raw.blocks))\n  \n  # Calcul de xtx.raw.C\n  xtx.raw.C <- xtx.raw - xtx.raw.I\n  \n  # Calcul du shrink.target global\n  shrink.target <- sum(diag(xtx.raw))/p\n  \n  # Créer des indices pour les boucles imbriquée",
        "s\n  alpha_indices <- expand.grid(replicate(n_blocks + 1, 1:nalpha, simplify = FALSE))\n  \n  # Boucle sur toutes les combinaisons d'indices alpha\n  for (row in 1:nrow(alpha_indices)) {\n    # Extraire les valeurs alpha actuelles\n    current_alphas <- alpha.all[as.numeric(alpha_indices[row, ])]\n    \n    # Les n_blocks premières alphas sont pour les blocs diagonaux\n    block_alphas <- current_alphas[1:n_blocks]\n    \n    # Le dernier alpha est pour xtx.raw.C\n    alpha_non_diag <- current_alphas[n_blocks + 1]\n   ",
        " \n    # Calcul du shrink.target pondéré\n    weighted_targets <- 0\n    weight_sum <- 0\n    for (i in 1:n_blocks) {\n      weighted_targets <- weighted_targets + ((1-block_alphas[i])^2) * shrink.targets[i]\n      weight_sum <- weight_sum + (1-block_alphas[i])^2\n    }\n    shrink.target_weighted <- weighted_targets / weight_sum\n    \n    # Construction de la matrice bloc-diagonale avec les alphas appliqués\n    scaled_blocks <- list()\n    for (i in 1:n_blocks) {\n      scaled_blocks[[i]] <- block_alphas[i] * xtx.",
        "raw.blocks[[i]]\n    }\n    xtx.raw.I_scaled <- as.matrix(do.call(Matrix::bdiag, scaled_blocks))\n    \n    # Construction de la matrice finale\n    xtx <- xtx.raw.I_scaled + alpha_non_diag * xtx.raw.C + \n           (n_blocks - sum(block_alphas)) * shrink.target_weighted * diag(p)\n    \n    # Vérification de la positivité\n    if (min(eigen(xtx, only.values = TRUE)$values) < 0) {\n      # Remplir avec 10^8 pour cette combinaison d'alphas et tous les lambdas\n      idx <- as.list(as.numeric(alpha_indices[row, ]))\n ",
        "     idx_str <- paste(paste(idx, collapse = \",\"), \",\", sep = \"\")\n      eval(parse(text = paste(\"DISCOM.tun.error[\", idx_str, \"] = 10^8\", sep = \"\")))\n    } else {\n      # Calcul des erreurs pour chaque lambda\n      beta.initial <- rep(0, p)\n      for (k in 1:nlambda) {\n        beta.cov <- as.vector(scout::crossProdLasso(xtx, xty, lambda.all[k], \n                                                     beta.init = beta.initial)$beta)\n        beta.initial <- beta.cov\n        intercept <- ifelse(itcp, mean(y) - sum",
        "(beta.cov * (xm/xs)), 0)\n        DISCOM.tun.values <- as.vector(as.matrix(x.tuning) %*% beta.cov) + intercept\n        \n        # Indexer correctement le tableau multidimensionnel\n        idx <- c(as.numeric(alpha_indices[row, ]), k)\n        idx_str <- paste(paste(idx, collapse = \",\"), sep = \"\")\n        eval(parse(text = paste(\"DISCOM.tun.error[\", idx_str, \"] = mean((y.tuning-DISCOM.tun.values)^2)\", sep = \"\")))\n      }\n    }\n  }\n  \n  # Trouver les paramètres optimaux\n  opt.index <- as.vector(which(DISCOM.tu",
        "n.error == min(DISCOM.tun.error), arr.ind = TRUE)[1, ])\n  train.error <- min(DISCOM.tun.error)\n  \n  # Extraire les valeurs alpha optimales\n  opt.alphas <- alpha.all[opt.index[1:(n_blocks+1)]]\n  block_alphas_opt <- opt.alphas[1:n_blocks]\n  alpha_non_diag_opt <- opt.alphas[n_blocks+1]\n  \n  # Extraire le lambda optimal\n  opt.lambda <- lambda.all[opt.index[n_blocks+2]]\n  \n  # Recalcul du shrink.target pondéré avec les alphas optimaux\n  weighted_targets <- 0\n  weight_sum <- 0\n  for (i in 1:n_blocks) {\n    weig",
        "hted_targets <- weighted_targets + ((1-block_alphas_opt[i])^2) * shrink.targets[i]\n    weight_sum <- weight_sum + (1-block_alphas_opt[i])^2\n  }\n  shrink.target_opt <- weighted_targets / weight_sum\n  \n  # Construction de la matrice bloc-diagonale optimale\n  scaled_blocks_opt <- list()\n  for (i in 1:n_blocks) {\n    scaled_blocks_opt[[i]] <- block_alphas_opt[i] * xtx.raw.blocks[[i]]\n  }\n  xtx.raw.I_opt <- as.matrix(do.call(Matrix::bdiag, scaled_blocks_opt))\n  \n  # Construction de la matrice finale optimale\n  x",
        "tx_opt <- xtx.raw.I_opt + alpha_non_diag_opt * xtx.raw.C + \n             (n_blocks - sum(block_alphas_opt)) * shrink.target_opt * diag(p)\n  \n  # Calcul du beta optimal\n  beta.cov <- as.vector(scout::crossProdLasso(xtx_opt, xty, opt.lambda)$beta)\n  beta.cov.lambda.max <- as.vector(scout::crossProdLasso(xtx_opt, xty, lmax)$beta)\n  intercept <- ifelse(itcp, mean(y) - sum(beta.cov * (xm/xs)), 0)\n  \n  # Prédiction sur l'ensemble de test\n  predict.test.values <- as.vector(x.test %*% beta.cov) + intercept\n  \n  # ",
        "Calcul des métriques de performance\n  DISCOM.test.error <- mean((y.test - predict.test.values)^2)\n  select <- sum(as.vector(as.integer(beta.cov != 0)))\n  \n  if (!is.null(beta)) {\n    DISCOM.fpr <- sum((beta == 0) & (beta.cov != 0))/sum(beta == 0)\n    DISCOM.fnr <- sum((beta != 0) & (beta.cov == 0))/sum(beta != 0)\n    DISCOM.est.error <- sqrt(sum((beta.cov - beta)^2))\n  } else {\n    DISCOM.fpr <- NA\n    DISCOM.fnr <- NA\n    DISCOM.est.error <- NA\n  }\n  \n  R2 <- cor(predict.test.values, y.test)^2\n  \n  end_ti",
        "me <- proc.time()\n  time_taken <- end_time - start_time\n  \n  # Préparation du résultat\n  a <- list(\n    'err' = DISCOM.tun.error, \n    'est.error' = DISCOM.est.error, \n    'lambda' = opt.lambda, \n    'alpha' = c(block_alphas_opt, alpha_non_diag_opt), \n    'train.error' = train.error, \n    'test.error' = DISCOM.test.error,\n    'y.pred' = predict.test.values,\n    'R2' = R2,\n    'a0' = intercept, \n    'a1' = beta.cov, \n    'select' = select, \n    'xtx' = xtx_opt, \n    'fpr' = DISCOM.fpr, \n    'lambda.all' = ",
        "lambda.all,\n    'beta.cov.lambda.max' = beta.cov.lambda.max,\n    'fnr' = DISCOM.fnr,\n    \"time\" = as.numeric(time_taken[3])\n  )\n  \n  return(a)\n}\n",
        "> ",
        "beta.true",
        " [1]  2  2  2  2  2  2  2  2  2  2  0  0  0  0  0  0  0  0  0  0  1  1  1  1\n[25]  1  1  1  1  1  1  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0  0  0\n[49]  0  0\n",
        "> ",
        "# Run AdapDiscom with default parameters",
        "> ",
        "result <- adapdiscom(",
        "+ ",
        "  beta = beta.true,      # True coefficients (optional, for evaluation)",
        "+ ",
        "  x = X.train,          # Training data",
        "+ ",
        "  y = y.train,          # Training response",
        "+ ",
        "  x.tuning = X.tuning,  # Tuning data",
        "+ ",
        "  y.tuning = y.tuning,  # Tuning response",
        "+ ",
        "  x.test = X.test,      # Test data",
        "+ ",
        "  y.test = y.test,      # Test response",
        "+ ",
        "  nlambda = 20,         # Number of lambda values",
        "+ ",
        "  nalpha = 10,          # Number of alpha values",
        "+ ",
        "  pp = pp,              # Block sizes",
        "+ ",
        "  robust = 0,           # Classical estimation",
        "+ ",
        "  standardize = TRUE,   # Standardize data",
        "+ ",
        "  itcp = TRUE          # Include intercept",
        "+ ",
        ")",
        "Error in standardize_x(as.matrix(x), robust = robust, k.value = k.value) : \n  could not find function \"standardize_x\"\n",
        "> ",
        "source(\"~/Desktop/AdapDiscom/AdapDiscomPackage/R/utility_functions.R\", echo=TRUE)",
        "\n> #' Generate Covariance Matrix\n> #'\n> #' @param p Integer, dimension of the covariance matrix\n> #' @param example Integer, type of covariance structu .... [TRUNCATED] \n\n> #' Compute X'X Matrix\n> #'\n> #' @param x Matrix, input data matrix\n> #' @param robust Integer, 0 for classical estimate, 1 for Huber robust estimate .... [TRUNCATED] \n\n> #' Compute X'y Vector\n> #'\n> #' @param x Matrix, input data matrix\n> #' @param y Vector, response vector\n> #' @param robust Integer, 0 for classical .... [TRUNCATED] \n\n>",
        " #' Standardize Matrix\n> #'\n> #' @param x Matrix, input data matrix\n> #' @param robust Integer, 0 for classical estimate, 1 for Huber robust estimate .... [TRUNCATED] \n\n> #' Apply Standardization to New Data\n> #'\n> #' @param x Matrix, input data matrix to be standardized\n> #' @param x.mean Vector, column means from tr .... [TRUNCATED] \n\n> #' Compute Lambda Max for L1 Regularization using KKT Conditions\n> #'\n> #' @param X Matrix, design matrix\n> #' @param y Vector, response vector\n> #' .... [TRUNCATED] \n\n> #",
        "' Get Block Indices\n> #'\n> #' @param pp Vector, block sizes\n> #' @return List with start and end indices for each block\n> #' @export\n> get_block_in .... [TRUNCATED] \n\n> #' Mean Imputation\n> #'\n> #' @param X Matrix with missing values\n> #' @return Matrix with missing values imputed by column means\n> im_mean <- functi .... [TRUNCATED] \n\n> #' SVD Imputation\n> #'\n> #' @param X Matrix with missing values\n> #' @return Matrix with missing values imputed using SVD\n> #' @export\n> im_svd <- f .... [TRUNCATED] \n",
        "> ",
        "# Run AdapDiscom with default parameters",
        "> ",
        "result <- adapdiscom(",
        "+ ",
        "  beta = beta.true,      # True coefficients (optional, for evaluation)",
        "+ ",
        "  x = X.train,          # Training data",
        "+ ",
        "  y = y.train,          # Training response",
        "+ ",
        "  x.tuning = X.tuning,  # Tuning data",
        "+ ",
        "  y.tuning = y.tuning,  # Tuning response",
        "+ ",
        "  x.test = X.test,      # Test data",
        "+ ",
        "  y.test = y.test,      # Test response",
        "+ ",
        "  nlambda = 20,         # Number of lambda values",
        "+ ",
        "  nalpha = 10,          # Number of alpha values",
        "+ ",
        "  pp = pp,              # Block sizes",
        "+ ",
        "  robust = 0,           # Classical estimation",
        "+ ",
        "  standardize = TRUE,   # Standardize data",
        "+ ",
        "  itcp = TRUE          # Include intercept",
        "+ ",
        ")",
        "Error in if (lambda.min.ratio <= 0 | lambda.min.ratio > 1 | is.null(lambda.min.ratio)) { : \n  argument is of length zero\n",
        "> ",
        "source(\"~/Desktop/AdapDiscom/AdapDiscomPackage/R/adapdiscom.R\", echo=TRUE)",
        "\n> #' AdapDiscom: Adaptive Discriminative Covariance Matrix Estimation\n> #'\n> #' @param beta Vector, true beta coefficients (optional)\n> #' @param x Ma .... [TRUNCATED] \n",
        "> ",
        "# Run AdapDiscom with default parameters",
        "> ",
        "result <- adapdiscom(",
        "+ ",
        "  beta = beta.true,      # True coefficients (optional, for evaluation)",
        "+ ",
        "  x = X.train,          # Training data",
        "+ ",
        "  y = y.train,          # Training response",
        "+ ",
        "  x.tuning = X.tuning,  # Tuning data",
        "+ ",
        "  y.tuning = y.tuning,  # Tuning response",
        "+ ",
        "  x.test = X.test,      # Test data",
        "+ ",
        "  y.test = y.test,      # Test response",
        "+ ",
        "  nlambda = 20,         # Number of lambda values",
        "+ ",
        "  nalpha = 10,          # Number of alpha values",
        "+ ",
        "  pp = pp,              # Block sizes",
        "+ ",
        "  robust = 0,           # Classical estimation",
        "+ ",
        "  standardize = TRUE,   # Standardize data",
        "+ ",
        "  itcp = TRUE          # Include intercept",
        "+ ",
        ")",
        "> ",
        "> ",
        "# View results",
        "> ",
        "print(result$MSE_test)",
        "NULL\n",
        "> ",
        "View(result)",
        "> ",
        "result[[\"R2\"]]",
        "         [,1]\n[1,] 0.820998\n",
        "> ",
        "# Optimal parameters",
        "> ",
        "cat(\"Optimal lambda:\", result$lambda, \"\\n\")",
        "Optimal lambda: 0.3515554 \n",
        "> ",
        "cat(\"Optimal alpha:\", result$alpha, \"\\n\")",
        "Optimal alpha: 0.1 0.4641589 0.1 0.4641589 \n",
        "> ",
        "> ",
        "# Performance metrics",
        "> ",
        "cat(\"Training error:\", result$train.error, \"\\n\")",
        "Training error: 13.72663 \n",
        "> ",
        "cat(\"Test error:\", result$test.error, \"\\n\")",
        "Test error: 22.12574 \n",
        "> ",
        "cat(\"R-squared:\", result$R2, \"\\n\")",
        "R-squared: 0.820998 \n",
        "> ",
        "> ",
        "# Model selection",
        "> ",
        "cat(\"Number of selected variables:\", result$select, \"\\n\")",
        "Number of selected variables: 38 \n",
        "> ",
        "> ",
        "# If true beta provided, evaluation metrics",
        "> ",
        "if (!is.null(beta.true)) {",
        "+ ",
        "  cat(\"Estimation error:\", result$est.error, \"\\n\")",
        "+ ",
        "  cat(\"False Positive Rate:\", result$fpr, \"\\n\")",
        "+ ",
        "  cat(\"False Negative Rate:\", result$fnr, \"\\n\")",
        "+ ",
        "}",
        "Estimation error: 4.315499 \nFalse Positive Rate: 0.65 \nFalse Negative Rate: 0.1666667 \n",
        "> ",
        "> ",
        "# Estimated coefficients",
        "> ",
        "head(result$a1)  # First 6 coefficients",
        "[1] 2.882359 1.315555 0.000000 1.683346 2.692348 3.300462\n\nRestarting R session...\n\n"
    ]
}